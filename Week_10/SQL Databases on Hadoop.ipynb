{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f6f7fc-c02d-466e-887e-7de43c676486",
   "metadata": {},
   "source": [
    "# SQL Databases on hadoop\n",
    "\n",
    "Relationele Database Management Systemen zijn traditioneel verticaal schaalbaar.\n",
    "Dit conflicteert met Big Data toepassingen waar we de voorkeur geven aan horizontale schaalbaarheid om onder andere de kosten te verlagen, de beschikbare rekenkracht of performantie en fout-tolerantie te verbeteren.\n",
    "Hierdoor kunnen de reeds gekende RDBMS niet gebruikt worden.\n",
    "\n",
    "De volgende populaire applicaties kunnen gebruikt worden om SQL te gebruiken op hadoop:\n",
    "* Apache Hive\n",
    "* Cloudera Impala\n",
    "* Presto\n",
    "* Shark\n",
    "\n",
    "Hierna gaan we een kort overzicht geven van al deze applicaties en daarna focussen we op een toepassingen van Apache Hive.\n",
    "\n",
    "## Apache Hive\n",
    "\n",
    "Deze applicatie is ontwikkeld door Facebook als **datawarehouse framework** voor interne toepassingen en is snel zeer populair geworden om queries uit te voeren op Hadoop.\n",
    "Het is belangrijk om in gedachten te houden dat hoewel Hive een **SQL-like querying omgeving** aanbiedt, dat er in de achtergrond een **MapReduce methodologie** gebruikt wordt om de database te bevragen.\n",
    "Dit wil zeggen dat de **queries gecompileerd moeten worden naar MapReduce toepassingen**.\n",
    "Hive ondersteund ook gebruikers-gedefineerde functies en laat toe om gecomprimeerde data te verwerken.\n",
    "Momenteel wordt Hive verder verbeterd en uitgebreid door HortonWorks (Cloudera) dat een nieuwe backend aan het uitwerken is (Tez Project) om de responstijd van Hive te verbeteren.\n",
    "\n",
    "Voordelen:\n",
    "* Op bijna alle Hadoop installaties standaard geinstalleerd\n",
    "* Goede tool om te proberen door minimale start-investering (gratis)\n",
    "\n",
    "Nadelen:\n",
    "* Niet meest snelle manier door overhead van MapReduce (batch processing)\n",
    "* Enkel 4 file-formats ondersteund:\n",
    " * Text, SequenceFile, ORC, RCFile\n",
    "\n",
    "## Cloudera Impala\n",
    "\n",
    "Maakt het mogelijk om interactieve SQL queries uit te voeren op HDFS en HBase. \n",
    "Impala voert **queries uit in real time** en verbeterd daardoor de performantie  door geen batch processing te gebruiken.\n",
    "Daarnaast wordt ook het **gebruik van verscheidene SQL-based bedrijfsanalyse tools mogelijk** gemaakt.\n",
    "Deze applicatie is een open source applicatie ontwikkeld door Cloudera.\n",
    "\n",
    "Voordelen:\n",
    "* Sneller dan Hive\n",
    "* Ondersteund cloud based architecture door Amazon's Elastic MapReduce\n",
    "* Is compatibel met ANSI SQL (standaard SQL standaard)\n",
    "* Integratie met business intelligence tools mogelijk\n",
    "\n",
    "Nadelen:\n",
    "* Moeilijker op te zetten\n",
    "* Volledige kracht maar beschikbaar bij gebruik van Parquet file format\n",
    "* Geen support voor YARN\n",
    "* Vereist installatie van daemons op elke node\n",
    "\n",
    "## Presto\n",
    "\n",
    "Een tweede applicatie ontwikkeld door Facebook.\n",
    "Ook deze applicatie is open source.\n",
    "Deze applicatie is geschreven in Java en heeft een groot aantal kenmerken gemeen met Impala, bijvoorbeeld:\n",
    "* Een interactieve ervaring\n",
    "* Moeiljk om op te zetten (installatie op de verscheidene nodes)\n",
    "* Vereist een specifiek file format voor data opslag (RCFile)\n",
    "\n",
    "Daarnaast biedt Presto wel compatibiliteit met de Hive meta-store en laat Presto toe om data van verscheidene bronnen te combineren.\n",
    "Het grootste verschil met Impala is dat Presto niet ondersteund wordt door veel leverancies van cloud-toepassingen, ook al maken reeds een aantal grote bedrijven er gebruik van (bijvoorbeeld AirBnb en Dropbox).\n",
    "\n",
    "## Shark\n",
    "\n",
    "Deze applicatie is ontstaan om een alternatief te bieden voor Hive met MapReduce.\n",
    "Het doel was om alle functionaliteiten van Hive te behouden maar de performantie te verbeteren.\n",
    "Deze tool is geschreven in Scala door UC Berkeley en zoals de naam doet vermoeden maakt het gebruik van **Spark**.\n",
    "Tot op een zeker punt kan Shark de performantie van Hive verbeteren maar de **schaalbaarheid van de tool** is niet zo goed als Hive.\n",
    "Dit komt omdat het **gebouwd is boven op Hive** waardoor het de complexe codebase van Hive heeft overgeerfd heeft.\n",
    "Het onderhoud en aanpassen van deze codebase zonder in te boeten op performantie is echter niet eenvoudig.\n",
    "\n",
    "## Spark SQL\n",
    "\n",
    "Dit onderdeel van Spark biedt de mogelijkheid aan om Spark Queries uit te voeren op ingeladen Dataframes.\n",
    "Omdat dit gebruik maakt van Spark biedt het veel voordelen en is de performantie beter dan tools die gebruik maken van MapReduce.\n",
    "Het grootste nadeel is echter dat deze data niet standaard opgeslagen wordt op een harde schrijf.\n",
    "Het is vrij eenvoudig om deze dataframes/tabellen op te slaan als bijvoorbeeld csv maar de relaties tussen kolommen van verschillende tabellen kan niet opgeslaan worden en vereist extra manueel werk om bij te houden.\n",
    "\n",
    "## Voorbeeld toepassing: Hive\n",
    "\n",
    "**LET OP:** Deze notebook moet je niet uitvoeren via jupyterlab. We gaan werken op een aparte cluster.\n",
    "\n",
    "Installeer hive door middel van de volgende stappen uit te voeren:\n",
    "* Maak een clone van de volgende repo: https://github.com/big-data-europe/docker-hive\n",
    "* Start de hive-cluster door middel van het volgende commando uit te voeren in een terminal in de folder van deze repository. Zoek daarna in de files na de correcte poort, username en wachtwoord van de hive cluster. Bestudeer ook de compose.yml file\n",
    "````\n",
    "    docker-compose up\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50610040-6c2b-401f-aff6-041b20199cec",
   "metadata": {},
   "source": [
    "Beantwoord nu de volgende vragen:\n",
    "\n",
    "**Vraag: Welke nodes worden aangemaakt in de compose file van de hive-cluster? Wat is de betekenis van de verschillende nodes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd15e3-68a3-4b4c-87ed-9001e6454580",
   "metadata": {},
   "source": [
    "Antwoord: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b74277-be27-40d2-bc4b-b240da32c3d8",
   "metadata": {},
   "source": [
    "**Vraag: Welke database wordt gebruikt voor de metadata van hive bij te houden?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0032429-70c6-4743-a479-88312d6c97dc",
   "metadata": {},
   "source": [
    "Antwoord: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187be768-d16f-4fae-857e-5086395c2a1b",
   "metadata": {},
   "source": [
    "**Vraag: Wat is de standaardpoort van de hive-server**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bf620-a347-4580-9e00-a20d8ab07337",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ba16209-0aa5-44d2-a87c-c354c845f999",
   "metadata": {},
   "source": [
    "**Vraag: Hoe start je de hive shell op de hive-server? Wat doet het commando dat je hiervoor gebruikt?** Tip: bestudeer de github repository en gebruik de terminal van de hive-server op docker desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a519c-ea85-488f-ad46-5ede4258ddb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e677f70a-4dba-4dc1-95a0-7f848d646337",
   "metadata": {},
   "source": [
    "Voer nu de volgende bewerkingen uit door de benodigde HQL-query uit te voeren.\n",
    "\n",
    "Bewerkingen:\n",
    "* Maak een tabel **customers** aan met de volgende kolommen\n",
    "    * id: int\n",
    "    * naam: string\n",
    "    * huisnummer: int\n",
    "    * straat: string\n",
    "    * bus: string\n",
    "    * Municipality: string\n",
    "    * County: string\n",
    "    * State: string\n",
    "    * zipcode: int\n",
    "    * country: string\n",
    "    * number: int\n",
    "    * home_type: string\n",
    "* Laad de data in de file /opt/hive/examples/files/customer_address.txt in in de nieuw aangemaakte tabel. Bekijk door de file explorer tab in docker desktop deze file. Merk op dat de splitsing van kolommen door het |-teken niet standaard is.\n",
    "* Selecteer alle rijen in de tabel en verifieer dat het correct ingeladen is.\n",
    "* Hoeveel rijen zijn er aanwezig in de tabel **customers**? Doe dit aan de hand van een hql query, niet uitlezen uit het vorige resultaat.\n",
    "* Wat is de grootste postcode?\n",
    "* Hoeveel rijen zijn er aanwezig voor elk type van huis?\n",
    "* Welke staten zijn aanwezig in de database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9e45e-126f-4eb6-936d-9e71001555f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 1: aanmaken tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4caf3-2016-4041-8f5d-bfd170d573e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 2: inladen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466b497-4e91-4abb-8179-5ff0f272390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 3: selecteer alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a718eef-e406-40af-8217-3574b0f1ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 4: aantal rijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "801b2e6e-2148-4360-a9ea-d2329c953589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 5: grootste postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "339f6838-188b-42fd-ae70-086d1042f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 6: aantal klanten per type huis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d389af-d5e7-4df3-b116-86db3d600b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bewerking 7: welke verschillende staten aanwezig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
